{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Q1. What are the three stages to build the hypotheses or model in machine learning?\n",
    ">The following are the three stages to build the hypothesis or model in Machine Learning:\n",
    "    1. Training of the model\n",
    "    2. Evaluation of the model\n",
    "    3. Deployment of the model\n",
    "\n",
    ">**1. Training of the model**\n",
    ">\n",
    ">   As pre-requisites to this stage,there should be a proper understaning of the business and the data provided. Also the given \n",
    ">    data should be pre-processed accordingly.\n",
    ">   \n",
    ">    Training of the model is done using the training dataset obtained from the original data.\n",
    ">    It includes steps such as Fitting the models, Optimization of Hyper-parameters and Model Selection.\n",
    ">    \n",
    ">\n",
    ">**2. Evaluation/Testing of the model**\n",
    ">\n",
    ">    Testing of the model is done using the test data and the model accuracy is determined.\n",
    ">\n",
    "> **3.Deployment of the model**\n",
    ">\n",
    ">    The model is applied in the given scenario.\n",
    "![caption](files/Model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What is the standard approach to supervised learning?\n",
    ">Supervised learning algorithms are trained using labeled examples, such as an input where the desired output is known.\n",
    ">\n",
    ">**STANDARD APPROACH**:\n",
    ">>**1. **The given data set is split into Training Dataset and the Test Data.<br><br>\n",
    ">>**2. **A function (or model)is created by using labeled training data that consists of input data and a wanted output.\n",
    ">  Since the wanted output is produced we call it the Supervised Learning.<br><br> \n",
    ">>**3. **Input feature representation of the learned function is determined.The number of features should not be too large,but should contain enough information to accurately predict the output.<br><br>\n",
    ">>**4. **The structure of the learned function and corresponding learning algorithm is determined.<br><br>\n",
    ">>**5. **The learning algorithm is performed on the gathered training set. Some supervised learning algorithms require the user to   determine certain control parameters. These parameters may be adjusted by optimizing performance on a subset (called a validation set) of the training set<br><br>\n",
    ">>**6. **The accuracy of the learned function is to be evaluated.The performance of the resulting function should be measured on the      test set that is separate from the training set.\n",
    "> \n",
    "\n",
    "![caption](files/image2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. What is Training set and Test set?\n",
    "\n",
    "> #### What is a Training Set?\n",
    "In machine learning, a training set is a **dataset used to train a model**.  In training the model, specific features are picked out from the training set.  These features are then incorporated into the model. Thereby, if the training set is labeled correctly, the model should be able to learn something from these features.\n",
    "\n",
    "> #### What is a Test Set?\n",
    "The test set is a **dataset used to measure how well the model performs at making predictions on that test set**. If the prediction scores for the test set are unreasonable, we’ll need to make some adjustments to our model and try again.\n",
    "\n",
    "![caption](files/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?\n",
    "\n",
    "> #### What is Ensemble Method?\n",
    "Ensemble learning helps improve machine learning results by combining several models. This approach allows the production of better predictive performance compared to a single model.\n",
    "Ensemble learning is used when you build component classifiers that are more accurate and independent from each other.<br><br>\n",
    "There are two types:<br>\n",
    "1.Sequential ensemble methods<br>\n",
    "2.Parallel ensemble methods\n",
    "> #### General Principle :\n",
    "The general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm in order to improve robustness over a single model.\n",
    "> #### What is Bagging?\n",
    "Bagging stands for bootstrap aggregation.\n",
    "Bagging is a method in ensemble for improving unstable estimation or classification schemes. Bagging can reduce errors by reducing the variance term.One way to reduce the variance of an estimate is to average together multiple estimates. For example, we can train M different trees on different subsets of the data (chosen randomly with replacement) and compute the ensemble:\n",
    "![caption](files/bagging.png)\n",
    "Bagging uses bootstrap sampling to obtain the data subsets for training the base learners. For aggregating the outputs of base learners, bagging uses voting for classification and averaging for regression.\n",
    "\n",
    "> #### What is Boosting?\n",
    "Boosting refers to a family of algorithms that are able to convert weak learners to strong learners.<br> \n",
    "The main principle of boosting is to fit a sequence of weak learners− models that are only slightly better than random guessing, such as small decision trees− to weighted versions of the data. More weight is given to examples that were misclassified by earlier rounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. How can you avoid overfitting ?\n",
    "> #### Methods to avoid Overfitting\n",
    "**1. Cross-Validation** : <br>\n",
    "Cross Validation in its simplest form is a one round validation, where we leave one sample as in-time validation and rest for training the model. But for keeping lower variance a higher fold cross validation is preferred.<br>\n",
    "Cross-validation allows you to tune hyperparameters with only your original training set. This allows you to keep your test set as a truly unseen dataset for selecting your final model.\n",
    "![caption](files/CV.png)<br><br>\n",
    "**2. Early Stopping** :<br> \n",
    "Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit.\n",
    "![caption](files/ES.png)<br><br>\n",
    "**3. Pruning** : <br>\n",
    "Pruning is used extensively while building CART models. It simply removes the nodes which add little predictive power for the problem in hand.<br><br>\n",
    "**4. Regularization** : <br>\n",
    "This is the technique we are going to discuss in more details. Simply put, it introduces a cost term for bringing in more features with the objective function. Hence, it tries to push the coefficients for many variables to zero and hence reduce cost term.<br><br>\n",
    "**5. Train with more data**<br><br>\n",
    "**6. Ensembling**<br>\n",
    "Ensembles are machine learning methods for combining predictions from multiple separate models. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
